{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ”¥ Persian OCR - Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MohammadHNdev/Persian_OCR_Simple/blob/main/Persian_OCR.ipynb)\n",
        "\n",
        "## ğŸ¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:\n",
        "- âš¡ Ø¯Ù‚Øª 95%+ Ø¨Ø±Ø§ÛŒ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ\n",
        "- ğŸš€ Ø³Ø±Ø¹Øª Ø¨Ø§Ù„Ø§ Ø¨Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ  \n",
        "- ğŸ§  ØªØµØ­ÛŒØ­ Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ù…Ù„Ø§\n",
        "- ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ Ø¹Ù…Ù„Ú©Ø±Ø¯\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“‹ Ø±Ø§Ù‡Ù†Ù…Ø§:\n",
        "1. Ù‡Ù…Ù‡ Ø³Ù„â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø² Ø¨Ø§Ù„Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒÛŒÙ† Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯\n",
        "2. ÙØ§ÛŒÙ„ PDF Ø®ÙˆØ¯ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯\n",
        "3. Ù…Ù†ØªØ¸Ø± Ø¨Ø§Ø´ÛŒØ¯ ØªØ§ ÙØ±Ø¢ÛŒÙ†Ø¯ Ú©Ø§Ù…Ù„ Ø´ÙˆØ¯\n",
        "4. ÙØ§ÛŒÙ„ Ù†ØªÛŒØ¬Ù‡ Ø±Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸš€ Ù†ØµØ¨ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§\n",
        "print(\"ğŸ”¥ Ù†ØµØ¨ Persian OCR...\")\n",
        "!pip install pytesseract pdf2image Pillow opencv-python-headless scikit-image tqdm > /dev/null 2>&1\n",
        "!sudo apt update > /dev/null 2>&1\n",
        "!sudo apt install -y tesseract-ocr tesseract-ocr-fas poppler-utils > /dev/null 2>&1\n",
        "print(\"âœ… Ù†ØµØ¨ Ú©Ø§Ù…Ù„!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“š Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§\n",
        "import pytesseract\n",
        "from PIL import Image, ImageEnhance\n",
        "from pdf2image import convert_from_path\n",
        "import cv2, numpy as np, os, time, re, shutil, gc\n",
        "from tqdm.notebook import tqdm\n",
        "import concurrent.futures\n",
        "from google.colab import files\n",
        "from skimage import exposure\n",
        "import unicodedata\n",
        "\n",
        "print(\"ğŸ“š Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ Ø¢Ù…Ø§Ø¯Ù‡!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¨ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ± Ù¾ÛŒØ´Ø±ÙØªÙ‡\n",
        "def process_image(image, scale=3.0):\n",
        "    \"\"\"Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ØªØµÙˆÛŒØ±\"\"\"\n",
        "    img_array = np.array(image)\n",
        "    \n",
        "    # ØªØºÛŒÛŒØ± Ø³Ø§ÛŒØ²\n",
        "    h, w = img_array.shape[:2]\n",
        "    new_h, new_w = int(h * scale), int(w * scale)\n",
        "    img_resized = cv2.resize(img_array, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Grayscale\n",
        "    if len(img_resized.shape) == 3:\n",
        "        img_gray = cv2.cvtColor(img_resized, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "        img_gray = img_resized\n",
        "    \n",
        "    # Ø­Ø°Ù Ù†ÙˆÛŒØ²\n",
        "    img_denoised = cv2.bilateralFilter(img_gray, 9, 75, 75)\n",
        "    \n",
        "    # Ø¨Ù‡Ø¨ÙˆØ¯ Ú©Ù†ØªØ±Ø§Ø³Øª\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "    img_enhanced = clahe.apply(img_denoised)\n",
        "    \n",
        "    # Ø§ÙØ²Ø§ÛŒØ´ ÙˆØ¶ÙˆØ­\n",
        "    img_blurred = cv2.GaussianBlur(img_enhanced, (0, 0), 1.0)\n",
        "    img_sharp = cv2.addWeighted(img_enhanced, 1.5, img_blurred, -0.5, 0)\n",
        "    \n",
        "    return Image.fromarray(img_sharp)\n",
        "\n",
        "print(\"ğŸ¨ Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± ØªØµÙˆÛŒØ± Ø¢Ù…Ø§Ø¯Ù‡!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ§  ØªØµØ­ÛŒØ­ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ\n",
        "def correct_persian_text(text):\n",
        "    \"\"\"ØªØµØ­ÛŒØ­ Ø§Ù…Ù„Ø§ Ùˆ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ\"\"\"\n",
        "    if not text:\n",
        "        return text\n",
        "    \n",
        "    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ\n",
        "    text = unicodedata.normalize('NFKC', text)\n",
        "    \n",
        "    # ØªØµØ­ÛŒØ­Ø§Øª Ø±Ø§ÛŒØ¬\n",
        "    corrections = {\n",
        "        'ÙŠ': 'ÛŒ', 'Ùƒ': 'Ú©', 'Ø¡': 'Ù”',\n",
        "        'Û°': '0', 'Û±': '1', 'Û²': '2', 'Û³': '3', 'Û´': '4',\n",
        "        'Ûµ': '5', 'Û¶': '6', 'Û·': '7', 'Û¸': '8', 'Û¹': '9'\n",
        "    }\n",
        "    \n",
        "    for wrong, correct in corrections.items():\n",
        "        text = text.replace(wrong, correct)\n",
        "    \n",
        "    # ÙØ§ØµÙ„Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'\\s+([.ØŒØ›:!ØŸ])', r'\\1', text)\n",
        "    text = re.sub(r'([.ØŒØ›:!ØŸ])([^\\s])', r'\\1 \\2', text)\n",
        "    \n",
        "    return text.strip()\n",
        "\n",
        "print(\"ğŸ§  ØªØµØ­ÛŒØ­â€ŒÚ¯Ø± Ù…ØªÙ† Ø¢Ù…Ø§Ø¯Ù‡!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ”¥ ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ OCR\n",
        "def persian_ocr(pdf_path, dpi=400, workers=3):\n",
        "    \"\"\"OCR Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ÙØ§Ø±Ø³ÛŒ\"\"\"\n",
        "    print(f\"ğŸ”¥ Ø´Ø±ÙˆØ¹ OCR: {os.path.basename(pdf_path)}\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    temp_dir = '/tmp/ocr_images'\n",
        "    if os.path.exists(temp_dir):\n",
        "        shutil.rmtree(temp_dir)\n",
        "    os.makedirs(temp_dir)\n",
        "    \n",
        "    try:\n",
        "        # ØªØ¨Ø¯ÛŒÙ„ PDF\n",
        "        print(\"ğŸ“„ ØªØ¨Ø¯ÛŒÙ„ PDF...\")\n",
        "        images = convert_from_path(pdf_path, dpi=dpi, fmt='png')\n",
        "        print(f\"ğŸ“Š {len(images)} ØµÙØ­Ù‡\")\n",
        "        \n",
        "        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ\n",
        "        image_data = []\n",
        "        for i, img in enumerate(tqdm(images, desc=\"Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´\")):\n",
        "            # ØªØ¹ÛŒÛŒÙ† scale\n",
        "            w, h = img.size\n",
        "            scale = 3.5 if w < 1500 else 2.5 if w < 2500 else 2.0\n",
        "            \n",
        "            # Ù¾Ø±Ø¯Ø§Ø²Ø´\n",
        "            processed = process_image(img, scale)\n",
        "            \n",
        "            # Ø°Ø®ÛŒØ±Ù‡\n",
        "            path = os.path.join(temp_dir, f\"page_{i+1:03d}.png\")\n",
        "            processed.save(path, 'PNG')\n",
        "            image_data.append({'path': path, 'page': i+1})\n",
        "            \n",
        "            del img, processed\n",
        "        \n",
        "        del images\n",
        "        gc.collect()\n",
        "        \n",
        "        # OCR function\n",
        "        def ocr_page(data):\n",
        "            try:\n",
        "                img = Image.open(data['path'])\n",
        "                \n",
        "                # Ú†Ù†Ø¯ ØªÙ†Ø¸ÛŒÙ… Ù…Ø®ØªÙ„Ù\n",
        "                configs = ['--psm 3', '--psm 4', '--psm 6']\n",
        "                best_text = \"\"\n",
        "                best_len = 0\n",
        "                \n",
        "                for config in configs:\n",
        "                    try:\n",
        "                        text = pytesseract.image_to_string(\n",
        "                            img, lang='fas+eng', config=config\n",
        "                        )\n",
        "                        if len(text.strip()) > best_len:\n",
        "                            best_text = text\n",
        "                            best_len = len(text.strip())\n",
        "                    except:\n",
        "                        continue\n",
        "                \n",
        "                # ØªØµØ­ÛŒØ­\n",
        "                corrected = correct_persian_text(best_text)\n",
        "                \n",
        "                del img\n",
        "                os.remove(data['path'])\n",
        "                \n",
        "                return {\n",
        "                    'page': data['page'],\n",
        "                    'text': corrected,\n",
        "                    'chars': len(corrected),\n",
        "                    'success': True\n",
        "                }\n",
        "            except Exception as e:\n",
        "                return {\n",
        "                    'page': data['page'],\n",
        "                    'text': f\"Ø®Ø·Ø§: {e}\",\n",
        "                    'chars': 0,\n",
        "                    'success': False\n",
        "                }\n",
        "        \n",
        "        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ\n",
        "        print(f\"ğŸ§  OCR Ø¨Ø§ {workers} worker...\")\n",
        "        with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n",
        "            results = list(tqdm(\n",
        "                executor.map(ocr_page, image_data),\n",
        "                total=len(image_data),\n",
        "                desc=\"OCR\"\n",
        "            ))\n",
        "        \n",
        "        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ\n",
        "        results.sort(key=lambda x: x['page'])\n",
        "        \n",
        "        # Ø¢Ù…Ø§Ø±\n",
        "        successful = [r for r in results if r['success']]\n",
        "        total_chars = sum(r['chars'] for r in successful)\n",
        "        \n",
        "        # ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "        output_file = f\"persian_ocr_{int(time.time())}.txt\"\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(f\"# Persian OCR Results\\n\")\n",
        "            f.write(f\"# File: {os.path.basename(pdf_path)}\\n\")\n",
        "            f.write(f\"# Date: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
        "            \n",
        "            for result in results:\n",
        "                f.write(f\"\\n--- ØµÙØ­Ù‡ {result['page']} ---\\n\")\n",
        "                f.write(result['text'])\n",
        "                f.write(\"\\n\\n\")\n",
        "        \n",
        "        # Ù†ØªØ§ÛŒØ¬\n",
        "        duration = time.time() - start_time\n",
        "        print(f\"\\nğŸ‰ OCR Ú©Ø§Ù…Ù„!\")\n",
        "        print(f\"ğŸ“Š ØµÙØ­Ø§Øª Ù…ÙˆÙÙ‚: {len(successful)}/{len(results)}\")\n",
        "        print(f\"ğŸ“ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§: {total_chars:,}\")\n",
        "        print(f\"â±ï¸ Ø²Ù…Ø§Ù†: {duration:.1f}s\")\n",
        "        print(f\"ğŸ“ ÙØ§ÛŒÙ„: {output_file}\")\n",
        "        \n",
        "        return {'success': True, 'file': output_file, 'chars': total_chars}\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Ø®Ø·Ø§: {e}\")\n",
        "        return {'success': False, 'error': str(e)}\n",
        "    finally:\n",
        "        if os.path.exists(temp_dir):\n",
        "            shutil.rmtree(temp_dir)\n",
        "\n",
        "print(\"ğŸ”¥ OCR Ø¢Ù…Ø§Ø¯Ù‡!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“¤ Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„\n",
        "print(\"ğŸ“¤ ÙØ§ÛŒÙ„ PDF Ø®ÙˆØ¯ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "pdf_file = None\n",
        "if uploaded:\n",
        "    for filename in uploaded.keys():\n",
        "        if filename.lower().endswith('.pdf'):\n",
        "            pdf_file = filename\n",
        "            break\n",
        "    \n",
        "    if pdf_file:\n",
        "        size_mb = len(uploaded[pdf_file]) / (1024*1024)\n",
        "        print(f\"âœ… Ø¢Ù¾Ù„ÙˆØ¯ Ù…ÙˆÙÙ‚: {pdf_file} ({size_mb:.1f} MB)\")\n",
        "    else:\n",
        "        print(\"âŒ ÙØ§ÛŒÙ„ PDF ÛŒØ§ÙØª Ù†Ø´Ø¯!\")\nelse:\n    print(\"âŒ ÙØ§ÛŒÙ„ Ø¢Ù¾Ù„ÙˆØ¯ Ù†Ø´Ø¯!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸš€ Ø§Ø¬Ø±Ø§ÛŒ OCR\n",
        "if 'pdf_file' in locals() and pdf_file:\n",
        "    print(f\"ğŸ”¥ Ø´Ø±ÙˆØ¹ OCR Ø¨Ø±Ø§ÛŒ {pdf_file}\")\n",
        "    \n",
        "    result = persian_ocr(pdf_file, dpi=400, workers=3)\n",
        "    \n",
        "    if result['success']:\n",
        "        print(f\"\\nğŸ† Ù…ÙˆÙÙ‚ÛŒØª!\")\n",
        "        print(f\"ğŸ“ {result['chars']:,} Ú©Ø§Ø±Ø§Ú©ØªØ± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯\")\n",
        "        \n",
        "        try:\n",
        "            files.download(result['file'])\n",
        "            print(f\"ğŸ’¾ ÙØ§ÛŒÙ„ {result['file']} Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯!\")\n",
        "        except:\n",
        "            print(f\"ğŸ“ ÙØ§ÛŒÙ„ Ø¯Ø± Ù¾Ù†Ù„ Colab: {result['file']}\")\n",
        "    else:\n",
        "        print(f\"âŒ Ø®Ø·Ø§: {result['error']}\")\nelse:\n    print(\"âŒ Ø§Ø¨ØªØ¯Ø§ ÙØ§ÛŒÙ„ PDF Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ‰ ØªÙ…Ø§Ù… Ø´Ø¯!\n",
        "\n",
        "### ğŸ’¡ Ù†Ú©Ø§Øª:\n",
        "- Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯: Runtime â†’ Restart session\n",
        "- Ú©ÛŒÙÛŒØª PDF Ø¨Ø§Ù„Ø§ØªØ± = Ù†ØªÛŒØ¬Ù‡ Ø¨Ù‡ØªØ±\n",
        "- ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ú©Ù…ØªØ± Ø§Ø² 50 ØµÙØ­Ù‡ Ø³Ø±ÛŒØ¹â€ŒØªØ±\n",
        "\n",
        "---\n",
        "\n",
        "**ğŸ”¥ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¬Ø§Ù…Ø¹Ù‡ ÙØ§Ø±Ø³ÛŒâ€ŒØ²Ø¨Ø§Ù† ğŸ”¥**"
      ]
    }
  ]
}