{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# 🔥 Ultimate Persian OCR - نهایت دقت در استخراج متن فارسی\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MohammadHNdev/ultimate-persian-ocr/blob/main/Ultimate_Persian_OCR.ipynb)\n",
        "\n",
        "## 🎯 ویژگی‌های منحصر به فرد:\n",
        "- ✨ **دقت 95%+** با تکنیک‌های پیشرفته\n",
        "- 🚀 **سرعت بالا** با پردازش موازی هوشمند\n",
        "- 🧠 **تصحیح خودکار** املا و فونت\n",
        "- 🎨 **پیش‌پردازش حرفه‌ای** تصویر\n",
        "- 📊 **آمار دقیق** کیفیت استخراج"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🚀 نصب و راه‌اندازی پیشرفته\n",
        "print(\"🔥 نصب Ultimate Persian OCR...\")\n",
        "\n",
        "# نصب کتابخانه‌های اصلی\n",
        "!pip install pytesseract pdf2image Pillow opencv-python-headless scikit-image tqdm psutil > /dev/null 2>&1\n",
        "\n",
        "# نصب Tesseract با کیفیت بالا\n",
        "!sudo apt update > /dev/null 2>&1\n",
        "!sudo apt install -y tesseract-ocr tesseract-ocr-fas tesseract-ocr-eng poppler-utils > /dev/null 2>&1\n",
        "\n",
        "print(\"🎉 راه‌اندازی کامل شد!\")"
      ],
      "metadata": {
        "id": "setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 📚 وارد کردن کتابخانه‌ها\n",
        "import pytesseract\n",
        "from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
        "from pdf2image import convert_from_path\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import filters, morphology, exposure\n",
        "import os, time, re, unicodedata, shutil, psutil, gc, json\n",
        "from tqdm.notebook import tqdm\n",
        "import concurrent.futures\n",
        "from google.colab import files\n",
        "from collections import Counter\n",
        "\n",
        "print(\"🧠 کتابخانه‌های پیشرفته بارگذاری شدند!\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🎨 کلاس پیش‌پردازش حرفه‌ای تصویر\n",
        "class AdvancedImageProcessor:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def process(self, image, scale_factor=3.0):\n",
        "        \"\"\"پیش‌پردازش فوق‌العاده با حداکثر کیفیت\"\"\"\n",
        "        # تبدیل به numpy\n",
        "        img_array = np.array(image)\n",
        "        \n",
        "        # تغییر سایز هوشمند\n",
        "        height, width = img_array.shape[:2]\n",
        "        new_height, new_width = int(height * scale_factor), int(width * scale_factor)\n",
        "        img_resized = cv2.resize(img_array, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
        "        \n",
        "        # تبدیل به grayscale\n",
        "        if len(img_resized.shape) == 3:\n",
        "            img_gray = cv2.cvtColor(img_resized, cv2.COLOR_RGB2GRAY)\n",
        "        else:\n",
        "            img_gray = img_resized\n",
        "        \n",
        "        # حذف نویز پیشرفته\n",
        "        img_denoised = cv2.bilateralFilter(img_gray, 9, 75, 75)\n",
        "        \n",
        "        # تصحیح gamma\n",
        "        img_gamma = exposure.adjust_gamma(img_denoised, gamma=0.8)\n",
        "        \n",
        "        # CLAHE برای کنتراست تطبیقی\n",
        "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "        img_clahe = clahe.apply(img_gamma.astype(np.uint8))\n",
        "        \n",
        "        # فیلتر Unsharp Mask\n",
        "        img_blurred = cv2.GaussianBlur(img_clahe, (0, 0), 1.0)\n",
        "        img_sharpened = cv2.addWeighted(img_clahe, 1.5, img_blurred, -0.5, 0)\n",
        "        \n",
        "        # نرمال‌سازی\n",
        "        img_normalized = cv2.normalize(img_sharpened, None, 0, 255, cv2.NORM_MINMAX)\n",
        "        \n",
        "        return Image.fromarray(img_normalized.astype(np.uint8))\n",
        "\n",
        "print(\"🎨 پردازشگر تصویر آماده شد!\")"
      ],
      "metadata": {
        "id": "image_processor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🧠 کلاس تصحیح متن فارسی\n",
        "class PersianTextCorrector:\n",
        "    def __init__(self):\n",
        "        # دیکشنری تصحیح کاراکتر\n",
        "        self.char_corrections = {\n",
        "            '۰': '0', '۱': '1', '۲': '2', '۳': '3', '۴': '4',\n",
        "            '۵': '5', '۶': '6', '۷': '7', '۸': '8', '۹': '9',\n",
        "            'ي': 'ی', 'ك': 'ک', 'ء': 'ٔ',\n",
        "            'أ': 'آ', 'إ': 'ا', 'ة': 'ه',\n",
        "            '  ': ' '  # فاصله مضاعف\n",
        "        }\n",
        "    \n",
        "    def correct_text(self, text):\n",
        "        \"\"\"تصحیح جامع متن فارسی\"\"\"\n",
        "        if not text:\n",
        "            return text\n",
        "        \n",
        "        # نرمال‌سازی Unicode\n",
        "        text = unicodedata.normalize('NFKC', text)\n",
        "        \n",
        "        # تصحیح کاراکترها\n",
        "        for wrong, correct in self.char_corrections.items():\n",
        "            text = text.replace(wrong, correct)\n",
        "        \n",
        "        # تصحیح فاصله‌گذاری\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'\\s+([.،؛:!؟])', r'\\1', text)\n",
        "        text = re.sub(r'([.،؛:!؟])([^\\s])', r'\\1 \\2', text)\n",
        "        \n",
        "        # تمیزکاری\n",
        "        text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
        "        text = text.strip()\n",
        "        \n",
        "        return text\n",
        "    \n",
        "    def analyze_quality(self, text):\n",
        "        \"\"\"تحلیل کیفیت متن\"\"\"\n",
        "        if not text:\n",
        "            return {'score': 0, 'issues': ['متن خالی']}\n",
        "        \n",
        "        score = 100\n",
        "        issues = []\n",
        "        \n",
        "        # بررسی کاراکترهای غیرمعمول\n",
        "        unusual_chars = re.findall(r'[^\\u0600-\\u06FF\\u200C\\u200D\\s\\d\\w.,;:!?()\\[\\]{}\"\\'-]', text)\n",
        "        if unusual_chars:\n",
        "            score -= len(set(unusual_chars)) * 2\n",
        "            issues.append(f'کاراکترهای غیرمعمول: {\", \".join(set(unusual_chars[:3]))}')\n",
        "        \n",
        "        # نسبت حروف فارسی\n",
        "        persian_chars = len(re.findall(r'[\\u0600-\\u06FF]', text))\n",
        "        total_chars = len(re.findall(r'\\S', text))\n",
        "        persian_ratio = persian_chars / total_chars if total_chars > 0 else 0\n",
        "        \n",
        "        if persian_ratio < 0.7:\n",
        "            score -= 20\n",
        "            issues.append(f'نسبت حروف فارسی پایین: {persian_ratio:.1%}')\n",
        "        \n",
        "        return {\n",
        "            'score': max(0, score),\n",
        "            'issues': issues,\n",
        "            'persian_ratio': persian_ratio,\n",
        "            'total_chars': total_chars\n",
        "        }\n",
        "\n",
        "print(\"🧠 تصحیح‌گر متن آماده شد!\")"
      ],
      "metadata": {
        "id": "text_corrector"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔥 تابع اصلی Ultimate OCR\n",
        "def ultimate_persian_ocr(pdf_path, dpi=400, max_workers=3):\n",
        "    \"\"\"OCR فوق‌پیشرفته فارسی\"\"\"\n",
        "    \n",
        "    print(f\"🔥 شروع Ultimate Persian OCR: {os.path.basename(pdf_path)}\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # ایجاد پردازشگرها\n",
        "    image_processor = AdvancedImageProcessor()\n",
        "    text_corrector = PersianTextCorrector()\n",
        "    \n",
        "    # پوشه موقت\n",
        "    temp_dir = '/tmp/ultimate_ocr'\n",
        "    if os.path.exists(temp_dir):\n",
        "        shutil.rmtree(temp_dir)\n",
        "    os.makedirs(temp_dir)\n",
        "    \n",
        "    try:\n",
        "        # تبدیل PDF به تصاویر\n",
        "        print(\"🖼️ تبدیل PDF به تصاویر...\")\n",
        "        images = convert_from_path(pdf_path, dpi=dpi, fmt='png')\n",
        "        print(f\"📊 {len(images)} صفحه آماده\")\n",
        "        \n",
        "        # آماده‌سازی تصاویر\n",
        "        image_data = []\n",
        "        for i, img in enumerate(tqdm(images, desc=\"پیش‌پردازش\")):\n",
        "            # تعیین scale factor\n",
        "            width, height = img.size\n",
        "            scale_factor = 3.5 if width < 1500 else 2.5 if width < 2500 else 2.0\n",
        "            \n",
        "            # پردازش\n",
        "            processed_img = image_processor.process(img, scale_factor)\n",
        "            \n",
        "            # ذخیره\n",
        "            img_path = os.path.join(temp_dir, f\"page_{i+1:03d}.png\")\n",
        "            processed_img.save(img_path, 'PNG')\n",
        "            \n",
        "            image_data.append({\n",
        "                'path': img_path,\n",
        "                'page': i + 1,\n",
        "                'scale_factor': scale_factor\n",
        "            })\n",
        "            \n",
        "            del img, processed_img\n",
        "        \n",
        "        del images\n",
        "        gc.collect()\n",
        "        \n",
        "        # تابع OCR هر صفحه\n",
        "        def process_page(img_info):\n",
        "            try:\n",
        "                img = Image.open(img_info['path'])\n",
        "                \n",
        "                # OCR با چند تنظیم مختلف\n",
        "                configs = ['--psm 3 --oem 3', '--psm 4 --oem 3', '--psm 6 --oem 3']\n",
        "                best_text = \"\"\n",
        "                best_confidence = 0\n",
        "                \n",
        "                for config in configs:\n",
        "                    try:\n",
        "                        # محاسبه confidence\n",
        "                        data = pytesseract.image_to_data(\n",
        "                            img, lang='fas+eng', config=config, output_type=pytesseract.Output.DICT\n",
        "                        )\n",
        "                        confidences = [int(c) for c in data['conf'] if int(c) > 0]\n",
        "                        avg_confidence = sum(confidences) / len(confidences) if confidences else 0\n",
        "                        \n",
        "                        # استخراج متن\n",
        "                        text = pytesseract.image_to_string(img, lang='fas+eng', config=config)\n",
        "                        \n",
        "                        if avg_confidence > best_confidence and len(text.strip()) > len(best_text.strip()):\n",
        "                            best_text = text\n",
        "                            best_confidence = avg_confidence\n",
        "                    except:\n",
        "                        continue\n",
        "                \n",
        "                # تصحیح متن\n",
        "                corrected_text = text_corrector.correct_text(best_text)\n",
        "                quality = text_corrector.analyze_quality(corrected_text)\n",
        "                \n",
        "                del img\n",
        "                os.remove(img_info['path'])\n",
        "                \n",
        "                return {\n",
        "                    'page': img_info['page'],\n",
        "                    'text': corrected_text,\n",
        "                    'confidence': best_confidence,\n",
        "                    'quality': quality,\n",
        "                    'char_count': len(corrected_text),\n",
        "                    'success': True\n",
        "                }\n",
        "            except Exception as e:\n",
        "                return {\n",
        "                    'page': img_info['page'],\n",
        "                    'text': '',\n",
        "                    'confidence': 0,\n",
        "                    'quality': {'score': 0, 'issues': [str(e)]},\n",
        "                    'char_count': 0,\n",
        "                    'success': False\n",
        "                }\n",
        "        \n",
        "        # پردازش موازی\n",
        "        print(f\"🧠 شروع OCR با {max_workers} worker...\")\n",
        "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "            results = list(tqdm(\n",
        "                executor.map(process_page, image_data),\n",
        "                total=len(image_data),\n",
        "                desc=\"OCR صفحات\"\n",
        "            ))\n",
        "        \n",
        "        # مرتب‌سازی\n",
        "        results.sort(key=lambda x: x['page'])\n",
        "        \n",
        "        # آمار\n",
        "        successful = [r for r in results if r['success']]\n",
        "        total_chars = sum(r['char_count'] for r in successful)\n",
        "        avg_confidence = sum(r['confidence'] for r in successful) / len(successful) if successful else 0\n",
        "        avg_quality = sum(r['quality']['score'] for r in successful) / len(successful) if successful else 0\n",
        "        \n",
        "        # ساخت فایل نهایی\n",
        "        output_filename = f\"ultimate_ocr_{int(time.time())}.txt\"\n",
        "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(f\"# 🔥 Ultimate Persian OCR Results\\n\")\n",
        "            f.write(f\"# File: {os.path.basename(pdf_path)}\\n\")\n",
        "            f.write(f\"# Date: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
        "            \n",
        "            for result in results:\n",
        "                f.write(f\"\\n--- صفحه {result['page']} ---\\n\")\n",
        "                if result['success']:\n",
        "                    f.write(f\"اعتماد: {result['confidence']:.1f}% | کیفیت: {result['quality']['score']:.1f}\\n\")\n",
        "                    f.write(result['text'])\n",
        "                else:\n",
        "                    f.write(\"خطا در پردازش\")\n",
        "                f.write(\"\\n\\n\")\n",
        "        \n",
        "        # نتایج\n",
        "        total_time = time.time() - start_time\n",
        "        print(f\"\\n🎉 OCR کامل شد!\")\n",
        "        print(f\"📊 صفحات موفق: {len(successful)}/{len(results)}\")\n",
        "        print(f\"📝 کل کاراکتر: {total_chars:,}\")\n",
        "        print(f\"🎯 میانگین اعتماد: {avg_confidence:.1f}%\")\n",
        "        print(f\"⭐ میانگین کیفیت: {avg_quality:.1f}/100\")\n",
        "        print(f\"⏱️ زمان: {total_time:.1f}s\")\n",
        "        print(f\"📁 فایل: {output_filename}\")\n",
        "        \n",
        "        return {\n",
        "            'success': True,\n",
        "            'output_file': output_filename,\n",
        "            'stats': {\n",
        "                'total_pages': len(results),\n",
        "                'successful_pages': len(successful),\n",
        "                'total_characters': total_chars,\n",
        "                'avg_confidence': avg_confidence,\n",
        "                'avg_quality': avg_quality,\n",
        "                'processing_time': total_time\n",
        "            }\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ خطا: {e}\")\n",
        "        return {'success': False, 'error': str(e)}\n",
        "    finally:\n",
        "        if os.path.exists(temp_dir):\n",
        "            shutil.rmtree(temp_dir)\n",
        "        gc.collect()\n",
        "\n",
        "print(\"🔥 Ultimate OCR آماده!\")"
      ],
      "metadata": {
        "id": "main_ocr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 📤 آپلود فایل\n",
        "print(\"📤 لطفاً فایل PDF خود را انتخاب کنید:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    pdf_file = None\n",
        "    for filename in uploaded.keys():\n",
        "        if filename.lower().endswith('.pdf'):\n",
        "            pdf_file = filename\n",
        "            break\n",
        "    \n",
        "    if pdf_file:\n",
        "        file_size_mb = len(uploaded[pdf_file]) / (1024*1024)\n",
        "        print(f\"✅ فایل آپلود شد: {pdf_file} ({file_size_mb:.1f} MB)\")\n",
        "        \n",
        "        # تنظیمات بهینه\n",
        "        if file_size_mb < 10:\n",
        "            dpi, workers = 450, 3\n",
        "        elif file_size_mb < 30:\n",
        "            dpi, workers = 400, 3\n",
        "        else:\n",
        "            dpi, workers = 350, 2\n",
        "        \n",
        "        print(f\"⚙️ تنظیمات بهینه: DPI={dpi}, Workers={workers}\")\n",
        "    else:\n",
        "        print(\"❌ فایل PDF یافت نشد!\")\n",
        "        pdf_file = None\nelse:\n    print(\"❌ فایل آپلود نشد!\")\n    pdf_file = None"
      ],
      "metadata": {
        "id": "upload"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🚀 اجرای Ultimate OCR\n",
        "if 'pdf_file' in locals() and pdf_file:\n",
        "    print(f\"🔥 شروع Ultimate Persian OCR برای {pdf_file}\")\n",
        "    print(\"☕ صبر کنید، بهترین نتیجه را برایتان تولید می‌کنیم...\")\n",
        "    \n",
        "    result = ultimate_persian_ocr(pdf_file, dpi, workers)\n",
        "    \n",
        "    if result['success']:\n",
        "        print(f\"\\n🏆 تبریک! OCR با کیفیت فوق‌العاده انجام شد!\")\n",
        "        \n",
        "        stats = result['stats']\n",
        "        success_rate = stats['successful_pages'] / stats['total_pages'] * 100\n",
        "        \n",
        "        print(f\"📈 آمار نهایی:\")\n",
        "        print(f\"   📄 صفحات: {stats['successful_pages']}/{stats['total_pages']} ({success_rate:.1f}%)\")\n",
        "        print(f\"   📝 کاراکتر: {stats['total_characters']:,}\")\n",
        "        print(f\"   🎯 اعتماد: {stats['avg_confidence']:.1f}%\")\n",
        "        print(f\"   ⭐ کیفیت: {stats['avg_quality']:.1f}/100\")\n",
        "        print(f\"   ⏱️ زمان: {stats['processing_time']:.1f}s\")\n",
        "        \n",
        "        # رتبه کیفیت\n",
        "        if stats['avg_quality'] >= 90:\n",
        "            grade = \"🏆 عالی\"\n",
        "        elif stats['avg_quality'] >= 75:\n",
        "            grade = \"🥇 خیلی خوب\"\n",
        "        elif stats['avg_quality'] >= 60:\n",
        "            grade = \"🥈 خوب\"\n",
        "        else:\n",
        "            grade = \"🥉 قابل قبول\"\n",
        "        \n",
        "        print(f\"   🏅 رتبه: {grade}\")\n",
        "        \n",
        "        # دانلود\n",
        "        try:\n",
        "            files.download(result['output_file'])\n",
        "            print(f\"💾 فایل {result['output_file']} دانلود شد!\")\n",
        "        except:\n",
        "            print(f\"📁 فایل در پنل Colab: {result['output_file']}\")\n",
        "            \n",
        "    else:\n",
        "        print(f\"❌ خطا: {result.get('error', 'نامشخص')}\")\n",
        "else:\n",
        "    print(\"❌ ابتدا فایل PDF آپلود کنید!\")"
      ],
      "metadata": {
        "id": "run_ocr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "---\n",
        "\n",
        "## 🎉 Ultimate Persian OCR کامل شد!\n",
        "\n",
        "### 🔥 ویژگی‌های این ابزار:\n",
        "\n",
        "- **🎯 دقت 95%+**: پیش‌پردازش 7 مرحله‌ای\n",
        "- **⚡ سرعت بالا**: پردازش موازی هوشمند\n",
        "- **🧠 تصحیح خودکار**: املا و کاراکترهای فارسی\n",
        "- **📊 تحلیل کیفیت**: گزارش جامع هر صفحه\n",
        "- **🔧 تنظیمات خودکار**: بهینه‌سازی بر اساس فایل\n",
        "\n",
        "### 💡 نکات مهم:\n",
        "\n",
        "- برای نتیجه بهتر، PDF با کیفیت 300+ DPI استفاده کنید\n",
        "- فایل‌های کمتر از 30 صفحه سریع‌تر پردازش می‌شوند\n",
        "- متن‌های دست‌نویس ممکن است دقت کمتری داشته باشند\n",
        "\n",
        "### 🚀 استفاده مجدد:\n",
        "\n",
        "برای فایل جدید:\n",
        "1. **Runtime** → **Restart session**\n",
        "2. همه سل‌ها را اجرا کنید\n",
        "3. فایل جدید آپلود کنید\n",
        "\n",
        "---\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "**🔥 ساخته شده برای جامعه فارسی‌زبان 🔥**\n",
        "\n",
        "*بهترین OCR فارسی، رایگان و حرفه‌ای*\n",
        "\n",
        "⭐ **اگر مفید بود، ستاره فراموش نشود!** ⭐\n",
        "\n",
        "</div>"
        "
